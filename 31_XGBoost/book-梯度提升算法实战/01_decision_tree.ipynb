{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree**\n",
    "\n",
    "@Time: 2024-12-01<br>\n",
    "@Author: Rui Zhu<br>\n",
    "@Follow: 第2章 深入浅出决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import astrokit as ak\n",
    "ak.pandas_show_all_columns()\n",
    "\n",
    "dir_data = Path(\"/Users/rui/Code/Astronote/31_XGBoost/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 决策树\n",
    "- 为什么在XGBoost学习之前介绍决策树?\n",
    "    1. XGBoost是一种集成方法, 由不同的ML模型(基学习器)组合而成\n",
    "    2. 决策树是XGBoost最常用的基学习器\n",
    "- 决策树容易过拟合\n",
    "    1. 决策树能够创建成千上万个分支, 直到训练集的数据映射到正确的目标, 但这样的模型泛化能力不强\n",
    "    2. 解决方法1: 超参数微调\n",
    "    3. 解决方法2: 决策树集成, 即随机森林和XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 实战: 预测一个人的年收入是否达到5万美元以上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 93)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_census = pd.read_csv(dir_data / \"census_cleaned.csv\")\n",
    "df_census.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_census.iloc[:, :-1]\n",
    "y = df_census.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8139106402579457"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 偏差与方差\n",
    "- 偏差: 将模型应用到实际问题时所估计的误差\n",
    "    1. 模型对数据的拟合不足, 偏差较大\n",
    "- 方差: 模型在不同训练集上训练会发生多大变化.\n",
    "    1. 具有高方差的模型往往会过拟合\n",
    "- 机器学习应追求低偏差和低方差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 决策树的超参数\n",
    "- [官方文档DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n",
    "- 优先调整的超参数:\n",
    "    1. max_depth\n",
    "    2. max_features\n",
    "    3. min_samples_leaf\n",
    "    4. max_leaf_nodes\n",
    "    5. min_impurity_decrease\n",
    "    6. min_samples_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实战: 预测某天的自行车租赁数量\n",
    "- 基准测试, 说明单颗决策树很容易过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {}\n",
      "Training score: 1000.03\n",
      "Test score: 816.36\n"
     ]
    }
   ],
   "source": [
    "# 基准测试\n",
    "df = pd.read_csv(dir_data / \"bike_rentals_cleaned.csv\")\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def grid_serach(params={}, reg=DecisionTreeRegressor(random_state=42)):\n",
    "    grid_red = GridSearchCV(reg, params, scoring=\"neg_mean_squared_error\", \n",
    "    cv=5, n_jobs=-1)\n",
    "    grid_red.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_red.best_params_\n",
    "    best_score = np.sqrt(-grid_red.best_score_)\n",
    "\n",
    "    best_model = grid_red.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    print(f\"Best params: {best_params}\")\n",
    "    print(f\"Training score: {best_score:.2f}\")\n",
    "    print(f\"Test score: {test_rmse:.2f}\")\n",
    "\n",
    "grid_serach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 观察模型在训练集上的表现\n",
    "reg = DecisionTreeRegressor()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_train)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "reg_mse = mean_squared_error(y_train, y_pred)\n",
    "reg_rmse = np.sqrt(reg_mse)\n",
    "reg_rmse  # ! 说明模型完美拟合训练集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## max_depth (最大树深度)\n",
    "- 默认: none, 没有限制, 即单颗决策树可以无限分割, 容易过拟合\n",
    "- 使用网格搜索工具选择最佳超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 5}\n",
      "Training score: 906.15\n",
      "Test score: 858.24\n"
     ]
    }
   ],
   "source": [
    "params = {'max_depth': [None, 2, 3, 4, 5, 6, 8, 10, 20]}\n",
    "\n",
    "grid_serach(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## min_samples_leaf (叶节点的最小样本数量)\n",
    "- 默认: 1, 即叶节点可以由1个样本组成, 这样很容易过拟合\n",
    "- 增加其数量, 有助于减少过拟合的风险"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'min_samples_leaf': 10}\n",
      "Training score: 853.53\n",
      "Test score: 910.45\n"
     ]
    }
   ],
   "source": [
    "params = {'min_samples_leaf': [1, 2, 4, 6, 8, 10, 20, 30]}\n",
    "grid_serach(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': None, 'min_samples_leaf': 10}\n",
      "Training score: 853.53\n",
      "Test score: 910.45\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': [None, 2, 3, 4, 5, 6, 8, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 6, 8, 10, 20, 30]\n",
    "}\n",
    "grid_serach(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 决策树分类实战:预测心脏病"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_heart = pd.read_csv(dir_data / \"heart_disease.csv\")\n",
    "df_heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_heart.iloc[:, :-1]   \n",
    "y = df_heart.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基准模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurcy: [0.76 0.73 0.81 0.69 0.73]\n",
      "Mean accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=42)\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "print(f\"Accurcy: {np.round(scores, 2)}\")\n",
    "print(f\"Mean accuracy: {np.round(scores.mean(), 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参数选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def random_search_clf(params, runs=20):\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    rand_clf = RandomizedSearchCV(\n",
    "        clf, params, n_iter=runs, cv=5, n_jobs=5, \n",
    "        random_state=42\n",
    "        )\n",
    "    rand_clf.fit(X_train, y_train)\n",
    "    best_model = rand_clf.best_estimator_\n",
    "    best_score = rand_clf.best_score_\n",
    "    print(f\"Traning score: {best_score:.2f}\")\n",
    "    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test score: {accuracy:.2f}\")\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning score: 0.80\n",
      "Test score: 0.77\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 5,\n",
       " 'max_features': 0.75,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0005,\n",
       " 'min_samples_leaf': 0.01,\n",
       " 'min_samples_split': 4,\n",
       " 'min_weight_fraction_leaf': 0.005,\n",
       " 'monotonic_cst': None,\n",
       " 'random_state': 42,\n",
       " 'splitter': 'random'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'min_weight_fraction_leaf': [0.0, 0.0025, 0.005, 0.0075, 0.01], \n",
    "    'min_samples_split': [2, 3, 4, 5, 6, 8, 10], \n",
    "    'min_samples_leaf': [1, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1], \n",
    "    'min_impurity_decrease': [0.0, 0.0005, 0.005, 0.05, 0.1, 0.15, 0.2], \n",
    "    'max_leaf_nodes': [10, 15, 20, 25, 30, 35, 40, 45, 50, None], \n",
    "    'max_features': [None, 0.95, 0.90, 0.85, 0.80, 0.75, 0.7], \n",
    "    'max_depth': [None, 2, 3, 4, 5, 6, 8, 10, 20],\n",
    "    'min_weight_fraction_leaf': [0.0, 0.0025, 0.005, 0.0075, 0.01, 0.05]\n",
    "}\n",
    "\n",
    "best_model = random_search_clf(params, runs=20)\n",
    "best_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检查优化的模型的性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurcy: [0.82 0.78 0.83 0.79 0.77]\n",
      "Mean accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "model = best_model\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "print(f\"Accurcy: {np.round(scores, 2)}\")\n",
    "print(f\"Mean accuracy: {np.round(scores.mean(), 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征重要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('exang', np.float64(0.3073929485313097)),\n",
       " ('ca', np.float64(0.23768966305113415)),\n",
       " ('sex', np.float64(0.09381420780786087)),\n",
       " ('cp', np.float64(0.0858642434380593)),\n",
       " ('slope', np.float64(0.07750439180073812)),\n",
       " ('oldpeak', np.float64(0.07481278188102705)),\n",
       " ('thal', np.float64(0.07019042250056112)),\n",
       " ('trestbps', np.float64(0.024647943028019394)),\n",
       " ('age', np.float64(0.014574116934075365)),\n",
       " ('restecg', np.float64(0.013509281027214822)),\n",
       " ('chol', np.float64(0.0)),\n",
       " ('fbs', np.float64(0.0)),\n",
       " ('thalach', np.float64(0.0))]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dict = dict(zip(X.columns, model.feature_importances_))\n",
    "import operator\n",
    "sorted(feature_dict.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
