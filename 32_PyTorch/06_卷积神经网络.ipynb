{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f3fd262",
   "metadata": {},
   "source": [
    "**卷积神经网络 (Convolutional Nerual Network, CNN)**\n",
    "\n",
    "@ Date: 2025-04-06<br>\n",
    "@ Author: Rui Zhu<br>\n",
    "@ Note: <br> \n",
    "    1. CNN是一类强大的、为处理图像数据而设计的神经网络<br>\n",
    "    2. CNN需要的参数少于全连接架构的网络, 而且卷积容易使用GPU平行计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc51da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261d2053",
   "metadata": {},
   "source": [
    "---\n",
    "# 基本概念\n",
    "- 图像中有丰富的结构, CNN通过卷积层提取了图像的结构特征\n",
    "- 图像中的结构特性:\n",
    "    1. 平移不变性(Translation Invariance): 图像中的物体可以出现在任意位置, 识别物体不应关注其在图像中的具体位置\n",
    "    2. 局部性(Locality): 图像中的对象识别关注的是局部区域, 而不是整个图像\n",
    "- 从MLP到CNN(数学表示):\n",
    "    1. 已知二维输入图像$X_{i, j}$, 则MLP第一个隐藏层(特征图)可表示为:$$H_{i, j} = U_{i, j} + \\sum_k \\sum_l W_{i, j}^{k, l} X_{k, l}$$\n",
    "    2. 使用($k=i+a$, $l=j+b$)重新索引下标($k, l$): $$H_{i, j} = U_{i, j} + \\sum_a \\sum_b V_{i, j}^{a, b} X_{i+a, j+b}$$\n",
    "    3. 由平移不变性, 检测对象在输入图像中的平移反映在特征图中的平移, 即$U_{i, j}$和$V_{i, j}^{a, b}$不依赖于$(i, j)$: $$H_{i, j} = u + \\sum_a \\sum_b V^{a, b} X_{i+a, j+b}$$\n",
    "    Note:\n",
    "       - 这就是卷积的数学表达, $V^{a, b}$称为卷积核, 即卷积层的权重, 是可学习的参数\n",
    "       - $V^{a, b}$比$V_{i, j}^{a, b}$大幅缩减参数规模, 通过对象在图像中的平移不变性\n",
    "    4. 由局部性原则, 卷积区域比图像小, 由此可以继续改写为: $$H_{i, j} = u + \\sum_{a=-\\Delta}^{\\Delta} \\sum_{b=-\\Delta}^{\\Delta} V^{a, b} X_{i+a, j+b}$$\n",
    "    Note:\n",
    "        - 其中$\\Delta$是卷积核的半宽, 即5x5的卷积核, 半宽为2\n",
    "- 卷积与互相关\n",
    "    1. 数学中的卷积: $$(f*g)(x) = \\int f(z)g(x-z)dz$$\n",
    "        (对于图像离散化)$$(f*g)(i, j) = \\sum_a \\sum_b f(a, b)g(i-a, j-b)$$\n",
    "    2. 数学中的互相关: $$(f*g)(x) = \\int f(z)g(x+z)dz$$\n",
    "        (对于图像离散化)$$(f*g)(i, j) = \\sum_a \\sum_b f(a, b)g(i+a, j+b)$$\n",
    "    3. 卷积和互相关是非常类似的操作, 差别在于是否反转kernal\n",
    "    4. CNN中使用的操作实际上是计算互相关\n",
    "- 通道(channel): 对于图像, 通道表示颜色信息的维度. 对于RGB图像, 通道数为3; 灰度图像, 通道数为1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7f7bc9",
   "metadata": {},
   "source": [
    "---\n",
    "# 卷积层\n",
    "- 严格来讲, 卷积层是错误的叫法, 实际表达的运算是互相关\n",
    "- 但两者差别只在于卷积需要水平和垂直翻转二维卷积核张量\n",
    "- 由于卷积核是从数据中学习得到的, 因此无论采用卷积还是互相关, 卷积层的输出不会受到影响\n",
    "- 在卷积层中, 输入张量和核张量通过互相关运算, 然后添加偏置标量生成输出张量\n",
    "- Feature Map: 卷积层也称特征映射\n",
    "- 元素: 卷积核张量上的每一个权重称为元素\n",
    "- 感受野(receptive field): 对于某一层的任意元素x, 其感受野指在向前传播期间可能影响x计算的所有元素(来自所有之前层)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a84665",
   "metadata": {},
   "source": [
    "## 定义互相关操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94597974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19., 25.],\n",
      "        [37., 43.]])\n"
     ]
    }
   ],
   "source": [
    "def coor2d(X, K):\n",
    "    \"\"\"\n",
    "    定义互相关运算\n",
    "    \"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = torch.sum(X[i:i + h, j:j + w] * K)\n",
    "    return Y\n",
    "\n",
    "X = torch.tensor([\n",
    "    [0, 1, 2], \n",
    "    [3, 4, 5], \n",
    "    [6, 7, 8]\n",
    "])\n",
    "K = torch.tensor([\n",
    "    [0, 1],\n",
    "    [2, 3]\n",
    "])\n",
    "Y = coor2d(X, K)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e6e355",
   "metadata": {},
   "source": [
    "## 定义卷积层\n",
    "- 卷积层的两个被训练参数: 卷积核, 标量偏置\n",
    "- 高度h和宽度w的卷积核称为hxw卷积核, 带有hxw卷积核的卷积层, 称为hxw卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f907477c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "    def forward(self, x):\n",
    "        return coor2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c748599",
   "metadata": {},
   "source": [
    "## 卷积层的应用举例: 边缘检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a48cbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 定义测试图像\n",
    "X = torch.ones((6, 8))\n",
    "X[:, 2:6] = 0\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11b9b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造卷积核, 水平两个元素相同输出0, 否则非0\n",
    "K = torch.tensor([[1, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23f91b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = coor2d(X, K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2292e5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord2d(X.T, K)  # 这个卷积核只能检测垂直边缘, 不能检测水平边缘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4777fe66",
   "metadata": {},
   "source": [
    "## 学习卷积核\n",
    "- 已知输入X和输出Y, 通过训练, 学习出这个卷积核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ad4eb2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 5.296\n",
      "epoch 2, loss 2.229\n",
      "epoch 3, loss 0.951\n",
      "epoch 4, loss 0.414\n",
      "epoch 5, loss 0.185\n",
      "epoch 6, loss 0.086\n",
      "epoch 7, loss 0.042\n",
      "epoch 8, loss 0.021\n",
      "epoch 9, loss 0.011\n",
      "epoch 10, loss 0.006\n",
      "epoch 11, loss 0.004\n",
      "epoch 12, loss 0.002\n",
      "epoch 13, loss 0.001\n",
      "epoch 14, loss 0.001\n",
      "epoch 15, loss 0.001\n",
      "epoch 16, loss 0.000\n",
      "epoch 17, loss 0.000\n",
      "epoch 18, loss 0.000\n",
      "epoch 19, loss 0.000\n",
      "epoch 20, loss 0.000\n",
      "Final kernel: tensor([[ 1.0007, -0.9992]])\n"
     ]
    }
   ],
   "source": [
    "# 构造卷积层\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=(1, 2), bias=False)\n",
    "\n",
    "# 使用4维输入和输出格式(批量大小, 通道, 高度, 宽度)\n",
    "X = X.reshape((1, 1, 6, 8))\n",
    "Y = Y.reshape((1, 1, 6, 7))\n",
    "lr = 0.03\n",
    "\n",
    "# 训练卷积层\n",
    "for i in range(20):\n",
    "    Y_hat = conv2d(X)\n",
    "    loss = (Y_hat - Y) ** 2\n",
    "    conv2d.zero_grad()\n",
    "    loss.sum().backward()\n",
    "    \n",
    "    conv2d.weight.data[:] -= lr * conv2d.weight.grad\n",
    "    print(f\"epoch {i + 1}, loss {loss.sum():.3f}\")\n",
    "\n",
    "print(f\"Final kernel: {conv2d.weight.data.reshape(1, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cab15bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
